# 模型配置

DeepChat 支持多种类型的模型配置，让你可以根据不同需求和场景选择合适的模型。本页面将详细介绍如何进行模型配置。

## 模型类型

DeepChat 支持以下几类模型：

### 内置模型

这些是 DeepChat 预装的轻量级模型，无需额外配置：

- 适用于基本对话和简单任务
- 不需要互联网连接
- 计算资源要求低
- 功能相对有限

### 本地模型

在你的计算机上运行的模型：

- 隐私保护更好，数据不会离开你的电脑
- 不需要持续的网络连接
- 需要较高的计算资源（特别是GPU）
- 支持多种开源模型

### API服务模型

通过互联网连接到第三方AI服务：

- 强大的处理能力和最新模型
- 需要网络连接
- 可能产生API使用费用
- 通常功能更加丰富

## 添加模型

### 添加本地模型

1. 打开设置 > 模型配置
2. 点击"添加模型" > "本地模型"
3. 填写以下信息：
   - 模型名称：为模型设置一个便于识别的名称
   - 模型类型：选择模型框架（如llama.cpp、ggml等）
   - 模型路径：选择模型文件的位置
   - 参数配置：根据需要调整上下文长度、线程数等参数
4. 点击"测试"确保模型正常工作
5. 点击"保存"完成添加

### 添加API服务模型

1. 打开设置 > 模型配置
2. 点击"添加模型" > "API服务"
3. 选择服务提供商（如OpenAI、Claude、百度等）
4. 填写以下信息：
   - 模型名称：为模型设置一个便于识别的名称
   - API密钥：从服务提供商获取的密钥
   - 模型选择：选择具体的模型版本
   - API基础URL：（可选）如果使用自定义端点
5. 点击"测试连接"确保API正常工作
6. 点击"保存"完成添加

## 管理模型

### 编辑模型

1. 打开设置 > 模型配置
2. 从列表中找到要编辑的模型
3. 点击"编辑"按钮
4. 修改相关设置
5. 点击"保存"

### 删除模型

1. 打开设置 > 模型配置
2. 从列表中找到要删除的模型
3. 点击"删除"按钮
4. 确认删除操作

### 设置默认模型

1. 打开设置 > 模型配置
2. 从列表中找到要设为默认的模型
3. 点击"设为默认"按钮

## 模型参数调整

每种模型都有一系列可调整的参数，这些参数会影响AI的行为和生成结果。

### 常见参数

- **温度**：控制输出的随机性。值越低，回答越确定性；值越高，回答越多样化创意。
- **最大生成长度**：控制回答的最大长度。
- **上下文长度**：模型能记住的对话历史长度。
- **Top-P 采样**：控制模型选择词汇的范围。
- **重复惩罚**：降低模型重复同一内容的可能性。

### 创建模型预设

对于常用的参数组合，你可以创建预设：

1. 打开设置 > 模型配置
2. 选择一个模型
3. 点击"创建预设"
4. 调整所需参数
5. 命名并保存预设

## 高级配置

### 自定义提示词模板

为模型设置系统提示词模板：

1. 打开设置 > 模型配置
2. 选择一个模型
3. 点击"高级设置"
4. 在"系统提示词"部分编辑模板
5. 保存设置

### 模型量化设置

对于本地模型，可以调整量化设置以平衡性能和资源占用：

1. 打开设置 > 模型配置
2. 选择本地模型
3. 点击"高级设置"
4. 在"量化设置"部分调整参数
5. 保存设置 