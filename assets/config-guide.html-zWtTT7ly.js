import{_ as i,c as r,e as l,a as n,b as a,d as t,w as u,r as e,o as c}from"./app-bgTXnUJ6.js";const d={},k={href:"https://ollama.ai/",target:"_blank",rel:"noopener noreferrer"},m={href:"https://lmstudio.ai/",target:"_blank",rel:"noopener noreferrer"};function v(q,s){const p=e("ExternalLinkIcon"),o=e("RouteLink");return c(),r("div",null,[s[16]||(s[16]=l(`<h1 id="模型配置指南" tabindex="-1"><a class="header-anchor" href="#模型配置指南"><span>模型配置指南</span></a></h1><p>本页面将详细指导您如何在 DeepChat 中配置和使用各类语言模型，包括商业 API 模型和本地开源模型。</p><h2 id="模型配置基础" tabindex="-1"><a class="header-anchor" href="#模型配置基础"><span>模型配置基础</span></a></h2><h3 id="访问模型设置" tabindex="-1"><a class="header-anchor" href="#访问模型设置"><span>访问模型设置</span></a></h3><p>在 DeepChat 中访问和管理模型配置：</p><ol><li><p><strong>模型配置面板</strong>：</p><ul><li>点击界面右上角的&quot;设置&quot;图标</li><li>选择&quot;模型&quot;选项卡</li><li>查看已配置的模型列表和添加新模型选项</li></ul></li><li><p><strong>对话中切换模型</strong>：</p><ul><li>在对话界面点击当前模型名称</li><li>从下拉菜单选择其他可用模型</li><li>或使用快捷键 <code>Ctrl+Shift+M</code>（Windows/Linux）或 <code>Cmd+Shift+M</code>（macOS）</li></ul></li><li><p><strong>设置默认模型</strong>：</p><ul><li>在模型配置页面选择一个模型</li><li>点击&quot;设为默认&quot;按钮</li><li>新对话将自动使用此模型</li></ul></li></ol><p><img src="https://deepchat.thinkinai.xyz/chat-screenshot.png" alt="模型配置界面"></p><p><em>这里应放置一张模型配置界面的截图，显示模型列表和配置选项。</em></p><h2 id="配置-api-模型" tabindex="-1"><a class="header-anchor" href="#配置-api-模型"><span>配置 API 模型</span></a></h2><h3 id="openai-模型配置" tabindex="-1"><a class="header-anchor" href="#openai-模型配置"><span>OpenAI 模型配置</span></a></h3><p>配置 OpenAI GPT 系列模型：</p><ol><li><p><strong>添加 OpenAI API</strong>：</p><ul><li>设置 → 模型 → 添加模型 → OpenAI</li><li>输入您的 OpenAI API 密钥</li><li>选择 API 类型（标准 API 或 Azure OpenAI）</li></ul></li><li><p><strong>基本设置</strong>：</p><ul><li>选择模型变体（GPT-4o、GPT-4、GPT-3.5-Turbo 等）</li><li>设置温度（0.0-2.0，值越低回答越确定）</li><li>配置最大响应长度（token 数）</li></ul></li><li><p><strong>高级参数</strong>：</p><ul><li>Top P（核心采样，控制词汇多样性）</li><li>频率惩罚（降低重复词的可能性）</li><li>存在惩罚（增加新概念的可能性）</li><li>系统消息自定义</li></ul></li><li><p><strong>模型特定功能</strong>：</p><ul><li>启用/禁用流式输出</li><li>配置函数调用功能</li><li>启用多模态支持（对于支持视觉的模型）</li></ul></li></ol><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token comment">// OpenAI 配置示例</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;GPT-4 Turbo&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;openai&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;gpt-4-turbo&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.7</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">4000</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_p&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;frequency_penalty&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;presence_penalty&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;streaming&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system_message&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是一个有帮助的助手。&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="anthropic-claude-配置" tabindex="-1"><a class="header-anchor" href="#anthropic-claude-配置"><span>Anthropic Claude 配置</span></a></h3><p>配置 Anthropic Claude 系列模型：</p><ol><li><p><strong>添加 Claude API</strong>：</p><ul><li>设置 → 模型 → 添加模型 → Anthropic</li><li>输入您的 Anthropic API 密钥</li><li>选择区域（如有必要）</li></ul></li><li><p><strong>模型选择和基本设置</strong>：</p><ul><li>选择模型变体（Claude 3 Opus/Sonnet/Haiku）</li><li>设置温度（0.0-1.0）</li><li>配置最大响应长度</li></ul></li><li><p><strong>高级参数</strong>：</p><ul><li>Top P 设置</li><li>Top K 设置（Claude 特有）</li><li>系统提示词优化</li></ul></li></ol><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token comment">// Claude 配置示例</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Claude 3 Sonnet&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;anthropic&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;claude-3-sonnet-20240229&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.5</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">4000</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_p&quot;</span><span class="token operator">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;streaming&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是Claude，一个由Anthropic开发的AI助手。请用简洁专业的方式回答问题。&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="google-gemini-配置" tabindex="-1"><a class="header-anchor" href="#google-gemini-配置"><span>Google Gemini 配置</span></a></h3><p>配置 Google Gemini 系列模型：</p><ol><li><p><strong>添加 Gemini API</strong>：</p><ul><li>设置 → 模型 → 添加模型 → Google AI</li><li>输入您的 Google AI API 密钥</li><li>选择 API 版本</li></ul></li><li><p><strong>基本设置</strong>：</p><ul><li>选择模型（Gemini 1.5 Pro、Gemini 1.0 Ultra 等）</li><li>设置温度和响应长度</li><li>配置安全设置</li></ul></li><li><p><strong>安全和使用限制</strong>：</p><ul><li>内容过滤级别设置</li><li>使用配额监控</li><li>API 请求频率限制</li></ul></li></ol><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token comment">// Gemini 配置示例</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Gemini Pro&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;google&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;gemini-1.0-pro&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;AIzaxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.4</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;maxOutputTokens&quot;</span><span class="token operator">:</span> <span class="token number">2048</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;topK&quot;</span><span class="token operator">:</span> <span class="token number">40</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;topP&quot;</span><span class="token operator">:</span> <span class="token number">0.95</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="配置本地模型" tabindex="-1"><a class="header-anchor" href="#配置本地模型"><span>配置本地模型</span></a></h2><h3 id="ollama-模型配置" tabindex="-1"><a class="header-anchor" href="#ollama-模型配置"><span>Ollama 模型配置</span></a></h3><p>使用 Ollama 运行本地模型：</p>`,24)),n("ol",null,[n("li",null,[s[4]||(s[4]=n("p",null,[n("strong",null,"安装 Ollama"),a("：")],-1)),n("ul",null,[n("li",null,[s[1]||(s[1]=a("从 ")),n("a",k,[s[0]||(s[0]=a("Ollama 官网")),t(p)]),s[2]||(s[2]=a(" 下载并安装"))]),s[3]||(s[3]=n("li",null,[a("拉取所需模型，例如："),n("code",null,"ollama pull llama3")],-1))])]),s[5]||(s[5]=l("<li><p><strong>在 DeepChat 中配置</strong>：</p><ul><li>设置 → 模型 → 添加模型 → Ollama</li><li>设置 API 地址（默认为 <code>http://localhost:11434</code>）</li><li>选择已拉取的模型</li></ul></li><li><p><strong>模型运行参数</strong>：</p><ul><li>设置上下文窗口大小</li><li>配置温度和采样参数</li><li>设置资源使用限制</li></ul></li><li><p><strong>高级 Ollama 选项</strong>：</p><ul><li>模板提示词格式自定义</li><li>使用自定义 Modelfile</li><li>配置系统提示词</li></ul></li>",3))]),s[17]||(s[17]=l(`<div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token comment">// Ollama 配置示例</span></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Llama 3 本地&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ollama&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;llama3&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;http://localhost:11434&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;context_size&quot;</span><span class="token operator">:</span> <span class="token number">8192</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system_prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是一个有帮助的AI助手，基于Llama 3模型。&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="localai-模型配置" tabindex="-1"><a class="header-anchor" href="#localai-模型配置"><span>LocalAI 模型配置</span></a></h3><p>使用 LocalAI 部署本地模型：</p><ol><li><p><strong>设置 LocalAI</strong>：</p><ul><li>安装并配置 LocalAI</li><li>下载并加载模型文件</li><li>启动 LocalAI 服务</li></ul></li><li><p><strong>在 DeepChat 中添加</strong>：</p><ul><li>设置 → 模型 → 添加模型 → 自定义 API</li><li>设置为 OpenAI 兼容接口</li><li>配置 LocalAI 服务器地址</li></ul></li><li><p><strong>性能优化</strong>：</p><ul><li>调整批处理大小和线程数</li><li>配置量化选项</li><li>内存使用限制设置</li></ul></li></ol><h3 id="lm-studio-模型配置" tabindex="-1"><a class="header-anchor" href="#lm-studio-模型配置"><span>LM Studio 模型配置</span></a></h3><p>使用 LM Studio 运行本地模型：</p>`,6)),n("ol",null,[n("li",null,[s[11]||(s[11]=n("p",null,[n("strong",null,"安装和设置 LM Studio"),a("：")],-1)),n("ul",null,[n("li",null,[s[7]||(s[7]=a("从 ")),n("a",m,[s[6]||(s[6]=a("LM Studio 网站")),t(p)]),s[8]||(s[8]=a(" 下载并安装"))]),s[9]||(s[9]=n("li",null,"导入模型或从库中下载",-1)),s[10]||(s[10]=n("li",null,"启动本地服务器",-1))])]),s[12]||(s[12]=l("<li><p><strong>在 DeepChat 中连接</strong>：</p><ul><li>设置 → 模型 → 添加模型 → 自定义 API</li><li>设置为 OpenAI 兼容接口</li><li>配置 LM Studio 本地服务器地址</li></ul></li><li><p><strong>自定义参数</strong>：</p><ul><li>配置 prompt 模板</li><li>调整性能参数</li><li>设置上下文管理选项</li></ul></li>",2))]),s[18]||(s[18]=l(`<h2 id="模型参数调优" tabindex="-1"><a class="header-anchor" href="#模型参数调优"><span>模型参数调优</span></a></h2><h3 id="关键参数解释" tabindex="-1"><a class="header-anchor" href="#关键参数解释"><span>关键参数解释</span></a></h3><p>了解并调整主要模型参数：</p><ol><li><p><strong>温度 (Temperature)</strong>：</p><ul><li><strong>范围</strong>：0.0-2.0，通常使用 0.0-1.0</li><li><strong>作用</strong>：控制回复的随机性和创造性</li><li><strong>建议</strong>： <ul><li>低温度 (0.1-0.3)：事实性回答，编码，逻辑任务</li><li>中温度 (0.4-0.7)：平衡的创意与准确性</li><li>高温度 (0.8-1.0)：创意写作，头脑风暴</li></ul></li></ul></li><li><p><strong>Top P（核心采样）</strong>：</p><ul><li><strong>范围</strong>：0.0-1.0</li><li><strong>作用</strong>：限制词汇选择范围，仅考虑累积概率达到 top_p 的词汇</li><li><strong>建议</strong>： <ul><li>精确任务：0.1-0.5</li><li>一般用途：0.7-0.9</li><li>创意生成：0.95-1.0</li></ul></li></ul></li><li><p><strong>最大长度 (Max Tokens)</strong>：</p><ul><li><strong>作用</strong>：限制模型回复的最大长度</li><li><strong>建议</strong>： <ul><li>简短回复：256-512</li><li>一般对话：1024-2048</li><li>长篇内容：4096+</li></ul></li></ul></li><li><p><strong>系统提示词</strong>：</p><ul><li><strong>作用</strong>：设置模型的行为指南和人格</li><li><strong>技巧</strong>： <ul><li>保持简洁明确</li><li>包含关键指令和限制</li><li>指定回复格式和风格</li></ul></li></ul></li></ol><h3 id="特定任务的推荐配置" tabindex="-1"><a class="header-anchor" href="#特定任务的推荐配置"><span>特定任务的推荐配置</span></a></h3><p>不同任务类型的优化配置：</p><table><thead><tr><th>任务类型</th><th>推荐模型</th><th>温度</th><th>Top P</th><th>其他参数</th></tr></thead><tbody><tr><td>编程辅助</td><td>GPT-4, CodeLlama</td><td>0.1-0.3</td><td>0.95</td><td>高频率惩罚</td></tr><tr><td>创意写作</td><td>Claude 3, GPT-4</td><td>0.7-0.9</td><td>0.95</td><td>较低频率惩罚</td></tr><tr><td>事实问答</td><td>GPT-4o, Claude 3</td><td>0.0-0.2</td><td>0.6</td><td>低存在惩罚</td></tr><tr><td>内容摘要</td><td>Claude 3, GPT-3.5</td><td>0.3-0.5</td><td>0.8</td><td>中等频率惩罚</td></tr><tr><td>头脑风暴</td><td>Claude 3 Opus, GPT-4</td><td>0.8-1.1</td><td>1.0</td><td>高存在惩罚</td></tr><tr><td>角色扮演</td><td>Claude 3, Llama 3</td><td>0.7-0.9</td><td>0.9</td><td>特定系统提示词</td></tr></tbody></table><h3 id="自定义配置模板" tabindex="-1"><a class="header-anchor" href="#自定义配置模板"><span>自定义配置模板</span></a></h3><p>保存和重用常用配置：</p><ol><li><p><strong>创建配置模板</strong>：</p><ul><li>设置模型参数为您偏好的值</li><li>点击&quot;保存为模板&quot;</li><li>命名并添加描述</li></ul></li><li><p><strong>应用配置模板</strong>：</p><ul><li>从模板库中选择配置</li><li>点击&quot;应用到当前模型&quot;</li><li>可选择应用部分或全部参数</li></ul></li><li><p><strong>分享配置模板</strong>：</p><ul><li>导出配置为 JSON 文件</li><li>通过设置 → 模型 → 导入配置添加他人的配置</li><li>导入后自动添加到模板库</li></ul></li></ol><h2 id="多模型管理" tabindex="-1"><a class="header-anchor" href="#多模型管理"><span>多模型管理</span></a></h2><h3 id="模型组和快速切换" tabindex="-1"><a class="header-anchor" href="#模型组和快速切换"><span>模型组和快速切换</span></a></h3><p>有效管理多个模型：</p><ol><li><p><strong>创建模型组</strong>：</p><ul><li>设置 → 模型 → 模型组 → 创建新组</li><li>命名并选择包含的模型</li><li>设置组显示顺序</li></ul></li><li><p><strong>快速切换</strong>：</p><ul><li>使用快捷键 <code>Ctrl+Shift+M</code> 打开模型选择器</li><li>按模型组过滤</li><li>使用方向键选择并按 Enter 确认</li></ul></li><li><p><strong>对话记忆</strong>：</p><ul><li>每个对话保留上次使用的模型</li><li>新对话使用全局默认模型</li><li>自动保存模型偏好设置</li></ul></li></ol><h3 id="模型回退和智能路由" tabindex="-1"><a class="header-anchor" href="#模型回退和智能路由"><span>模型回退和智能路由</span></a></h3><p>处理模型不可用或特定任务路由：</p><ol><li><p><strong>配置模型回退</strong>：</p><ul><li>为每个主要模型设置备选模型</li><li>当主模型不可用或出错时自动切换</li><li>设置恢复条件和通知选项</li></ul></li><li><p><strong>智能任务路由</strong>：</p><ul><li>基于任务类型自动选择模型</li><li>例如：代码问题路由到 CodeLlama</li><li>创意任务路由到 Claude 3 等</li></ul></li><li><p><strong>基于内容长度路由</strong>：</p><ul><li>配置长内容自动路由到大上下文模型</li><li>短问题使用快速响应模型</li><li>设置路由规则和阈值</li></ul></li></ol><h2 id="模型评估和监控" tabindex="-1"><a class="header-anchor" href="#模型评估和监控"><span>模型评估和监控</span></a></h2><h3 id="性能跟踪" tabindex="-1"><a class="header-anchor" href="#性能跟踪"><span>性能跟踪</span></a></h3><p>监控模型使用和性能：</p><ol><li><p><strong>使用统计</strong>：</p><ul><li>查看每个模型的使用频率</li><li>跟踪响应时间和质量</li><li>分析成本和效率</li></ul></li><li><p><strong>响应质量评估</strong>：</p><ul><li>通过反馈评分系统评估回复质量</li><li>比较不同模型的表现</li><li>识别特定任务的最佳模型</li></ul></li><li><p><strong>成本监控</strong>：</p><ul><li>跟踪 API 调用成本</li><li>设置使用限额和预算警报</li><li>优化成本性能比</li></ul></li></ol><h3 id="自动测试和基准" tabindex="-1"><a class="header-anchor" href="#自动测试和基准"><span>自动测试和基准</span></a></h3><p>评估模型性能的工具：</p><ol><li><p><strong>模型基准测试</strong>：</p><ul><li>运行标准测试集评估模型能力</li><li>比较不同模型在特定任务上的表现</li><li>根据结果优化配置</li></ul></li><li><p><strong>一致性检查</strong>：</p><ul><li>测试模型在相同提示下的一致性</li><li>评估不同参数设置的影响</li><li>识别最稳定的配置</li></ul></li></ol><h2 id="故障排除" tabindex="-1"><a class="header-anchor" href="#故障排除"><span>故障排除</span></a></h2><p>常见模型问题及解决方案：</p><table><thead><tr><th>问题</th><th>可能原因</th><th>解决方案</th></tr></thead><tbody><tr><td>API 连接失败</td><td>API 密钥无效；服务中断；网络问题</td><td>验证 API 密钥；检查服务状态；测试网络连接</td></tr><tr><td>本地模型崩溃</td><td>内存不足；显存溢出；模型损坏</td><td>减小批处理大小；使用更小模型；重新下载模型</td></tr><tr><td>模型输出截断</td><td>最大长度设置过低；上下文窗口限制</td><td>增加最大令牌数；减少输入长度；分段处理长任务</td></tr><tr><td>模型回复偏离</td><td>温度设置过高；系统提示词不明确</td><td>降低温度参数；优化系统提示词；使用更强大的模型</td></tr><tr><td>响应延迟过高</td><td>服务器负载；网络延迟；模型大小</td><td>使用本地缓存；切换到更快模型；优化网络连接</td></tr></tbody></table><h2 id="高级配置示例" tabindex="-1"><a class="header-anchor" href="#高级配置示例"><span>高级配置示例</span></a></h2><h3 id="openai-高级配置" tabindex="-1"><a class="header-anchor" href="#openai-高级配置"><span>OpenAI 高级配置</span></a></h3><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;GPT-4 专业配置&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;openai&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;gpt-4&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">8000</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_p&quot;</span><span class="token operator">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;presence_penalty&quot;</span><span class="token operator">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;frequency_penalty&quot;</span><span class="token operator">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;stop&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">&quot;\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;用户:&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;AI:&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;logit_bias&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token property">&quot;50256&quot;</span><span class="token operator">:</span> <span class="token number">-100</span></span>
<span class="line">  <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;streaming&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system_message&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是一位知识渊博、逻辑清晰的专业助手。请提供准确、具体且深入的回答。在回答前先分析问题的关键点，然后系统地组织你的思路。对于不确定的信息，请明确指出这是推测。&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;tools&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">      <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;function&quot;</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;function&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;search_knowledge_base&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;description&quot;</span><span class="token operator">:</span> <span class="token string">&quot;搜索内部知识库获取信息&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;parameters&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">          <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;object&quot;</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token property">&quot;properties&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token property">&quot;query&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">              <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span></span>
<span class="line">              <span class="token property">&quot;description&quot;</span><span class="token operator">:</span> <span class="token string">&quot;搜索查询&quot;</span></span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">          <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token property">&quot;required&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">&quot;query&quot;</span><span class="token punctuation">]</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="claude-高级配置" tabindex="-1"><a class="header-anchor" href="#claude-高级配置"><span>Claude 高级配置</span></a></h3><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Claude 创意助手&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;anthropic&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;claude-3-opus-20240229&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">5000</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_p&quot;</span><span class="token operator">:</span> <span class="token number">0.95</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_k&quot;</span><span class="token operator">:</span> <span class="token number">50</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;streaming&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是一位富有创造力和想象力的助手，专长于生成新颖、独特的创意内容。你的回答应该充满灵感，探索不同角度和可能性。在讨论创意主题时，请提供多种思路和选择，帮助用户拓展思维边界。同时，你应该用生动、引人入胜的语言表达你的想法，激发用户的灵感。请确保你的回答既有创意又有实用价值。&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="本地-ollama-高级配置" tabindex="-1"><a class="header-anchor" href="#本地-ollama-高级配置"><span>本地 Ollama 高级配置</span></a></h3><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Llama 3 编程助手&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ollama&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;codellama&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;http://localhost:11434&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;temperature&quot;</span><span class="token operator">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;num_ctx&quot;</span><span class="token operator">:</span> <span class="token number">8192</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;seed&quot;</span><span class="token operator">:</span> <span class="token number">42</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;repeat_penalty&quot;</span><span class="token operator">:</span> <span class="token number">1.1</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_k&quot;</span><span class="token operator">:</span> <span class="token number">40</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;top_p&quot;</span><span class="token operator">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;num_thread&quot;</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;system_prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;你是一位专业的编程助手，基于CodeLlama模型。请提供简洁、高效、符合最佳实践的代码和解释。优先考虑代码的可读性和可维护性。确保你提供的代码是完整的、可直接运行的，并解释关键部分。如果有多种解决方案，请指出最适合的方法并解释原因。&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,34)),n("p",null,[s[14]||(s[14]=a("下一步，您可以了解如何安全管理")),t(o,{to:"/guide/model-integration/api-keys.html"},{default:u(()=>s[13]||(s[13]=[a("API密钥")])),_:1,__:[13]}),s[15]||(s[15]=a("，确保模型访问的安全性和有效性。"))]),s[19]||(s[19]=n("p",null,[n("img",{src:"https://deepchat.thinkinai.xyz/chat-screenshot.png",alt:"模型配置指南"})],-1)),s[20]||(s[20]=n("p",null,[n("em",null,"这里应放置一张配置模型的步骤截图，展示如何添加和配置一个新模型。")],-1))])}const h=i(d,[["render",v]]),b=JSON.parse('{"path":"/guide/model-integration/config-guide.html","title":"模型配置指南","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"模型配置基础","slug":"模型配置基础","link":"#模型配置基础","children":[{"level":3,"title":"访问模型设置","slug":"访问模型设置","link":"#访问模型设置","children":[]}]},{"level":2,"title":"配置 API 模型","slug":"配置-api-模型","link":"#配置-api-模型","children":[{"level":3,"title":"OpenAI 模型配置","slug":"openai-模型配置","link":"#openai-模型配置","children":[]},{"level":3,"title":"Anthropic Claude 配置","slug":"anthropic-claude-配置","link":"#anthropic-claude-配置","children":[]},{"level":3,"title":"Google Gemini 配置","slug":"google-gemini-配置","link":"#google-gemini-配置","children":[]}]},{"level":2,"title":"配置本地模型","slug":"配置本地模型","link":"#配置本地模型","children":[{"level":3,"title":"Ollama 模型配置","slug":"ollama-模型配置","link":"#ollama-模型配置","children":[]},{"level":3,"title":"LocalAI 模型配置","slug":"localai-模型配置","link":"#localai-模型配置","children":[]},{"level":3,"title":"LM Studio 模型配置","slug":"lm-studio-模型配置","link":"#lm-studio-模型配置","children":[]}]},{"level":2,"title":"模型参数调优","slug":"模型参数调优","link":"#模型参数调优","children":[{"level":3,"title":"关键参数解释","slug":"关键参数解释","link":"#关键参数解释","children":[]},{"level":3,"title":"特定任务的推荐配置","slug":"特定任务的推荐配置","link":"#特定任务的推荐配置","children":[]},{"level":3,"title":"自定义配置模板","slug":"自定义配置模板","link":"#自定义配置模板","children":[]}]},{"level":2,"title":"多模型管理","slug":"多模型管理","link":"#多模型管理","children":[{"level":3,"title":"模型组和快速切换","slug":"模型组和快速切换","link":"#模型组和快速切换","children":[]},{"level":3,"title":"模型回退和智能路由","slug":"模型回退和智能路由","link":"#模型回退和智能路由","children":[]}]},{"level":2,"title":"模型评估和监控","slug":"模型评估和监控","link":"#模型评估和监控","children":[{"level":3,"title":"性能跟踪","slug":"性能跟踪","link":"#性能跟踪","children":[]},{"level":3,"title":"自动测试和基准","slug":"自动测试和基准","link":"#自动测试和基准","children":[]}]},{"level":2,"title":"故障排除","slug":"故障排除","link":"#故障排除","children":[]},{"level":2,"title":"高级配置示例","slug":"高级配置示例","link":"#高级配置示例","children":[{"level":3,"title":"OpenAI 高级配置","slug":"openai-高级配置","link":"#openai-高级配置","children":[]},{"level":3,"title":"Claude 高级配置","slug":"claude-高级配置","link":"#claude-高级配置","children":[]},{"level":3,"title":"本地 Ollama 高级配置","slug":"本地-ollama-高级配置","link":"#本地-ollama-高级配置","children":[]}]}],"git":{"createdTime":1742921049000,"updatedTime":1742921049000,"contributors":[{"name":"袁鑫","email":"eric.yuanxin@gmail.com","commits":1}]},"filePathRelative":"guide/model-integration/config-guide.md"}');export{h as comp,b as data};
