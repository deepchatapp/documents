import{_ as n,c as h,e as o,a as d,b as e,d as l,w as s,r as a,o as p}from"./app-C4bB1Ege.js";const u={},G={href:"https://deepchat.thinkinai.xyz/models",target:"_blank",rel:"noopener noreferrer"};function g(c,t){const i=a("ExternalLinkIcon"),r=a("RouteLink");return p(),h("div",null,[t[6]||(t[6]=o('<h1 id="支持的模型" tabindex="-1"><a class="header-anchor" href="#支持的模型"><span>支持的模型</span></a></h1><p>DeepChat 支持多种先进的语言模型，从商业云端API模型到本地部署的开源模型。本页面将提供完整的支持模型列表及其主要特性。</p><h2 id="商业云模型" tabindex="-1"><a class="header-anchor" href="#商业云模型"><span>商业云模型</span></a></h2><h3 id="openai-模型" tabindex="-1"><a class="header-anchor" href="#openai-模型"><span>OpenAI 模型</span></a></h3><p>OpenAI 提供的高性能模型，通过 API 使用：</p><table><thead><tr><th>模型</th><th>上下文窗口</th><th>主要优势</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>GPT-4o</td><td>128K 令牌</td><td>最新版本，多模态能力，性能强大</td><td>复杂任务，多模态交互，需要最高质量输出</td></tr><tr><td>GPT-4</td><td>8K/32K 令牌</td><td>推理能力强，生成质量高</td><td>学术写作，复杂推理，高要求内容生成</td></tr><tr><td>GPT-3.5-Turbo</td><td>4K/16K 令牌</td><td>响应速度快，成本较低</td><td>日常对话，简单任务，原型开发</td></tr><tr><td>GPT-4-Vision</td><td>128K 令牌</td><td>图像理解和分析能力</td><td>图像描述，视觉内容分析，多模态任务</td></tr></tbody></table><p><strong>API 特性</strong>：</p><ul><li>支持流式响应</li><li>函数调用功能</li><li>系统提示词优化</li><li>向量嵌入生成</li><li>使用配额和计费管理</li></ul><h3 id="anthropic-模型" tabindex="-1"><a class="header-anchor" href="#anthropic-模型"><span>Anthropic 模型</span></a></h3><p>Anthropic 提供的 Claude 系列模型：</p><table><thead><tr><th>模型</th><th>上下文窗口</th><th>主要优势</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>Claude 3 Opus</td><td>200K 令牌</td><td>最高性能，推理能力极强</td><td>专业研究，复杂分析，高质量创作</td></tr><tr><td>Claude 3 Sonnet</td><td>200K 令牌</td><td>平衡性能和速度</td><td>日常工作使用，一般内容创作</td></tr><tr><td>Claude 3 Haiku</td><td>200K 令牌</td><td>速度快，成本低</td><td>快速响应，简单任务，高频使用</td></tr><tr><td>Claude 2.1</td><td>100K 令牌</td><td>成熟稳定</td><td>需要稳定性的生产环境</td></tr></tbody></table><p><strong>API 特性</strong>：</p><ul><li>超长上下文窗口</li><li>音频和图像输入</li><li>较低的幻觉率</li><li>内置道德伦理考量</li></ul><h3 id="google-模型" tabindex="-1"><a class="header-anchor" href="#google-模型"><span>Google 模型</span></a></h3><p>Google 提供的 Gemini 系列模型：</p><table><thead><tr><th>模型</th><th>上下文窗口</th><th>主要优势</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>Gemini 1.5 Pro</td><td>128K 令牌</td><td>多模态能力强，长上下文理解</td><td>文档分析，多模态任务，长对话</td></tr><tr><td>Gemini 1.0 Ultra</td><td>32K 令牌</td><td>逻辑推理能力强</td><td>复杂问题解决，学术研究</td></tr><tr><td>Gemini 1.0 Pro</td><td>32K 令牌</td><td>平衡性能和效率</td><td>一般工作场景，内容创建</td></tr><tr><td>Gemini 1.0 Flash</td><td>32K 令牌</td><td>高速响应</td><td>即时回复，简单任务</td></tr></tbody></table><p><strong>API 特性</strong>：</p><ul><li>多模态输入支持</li><li>流式输出</li><li>与 Google 服务集成</li><li>安全过滤功能</li></ul><h3 id="其他商业模型" tabindex="-1"><a class="header-anchor" href="#其他商业模型"><span>其他商业模型</span></a></h3><p>其他可通过 API 接入的商业模型：</p><table><thead><tr><th>模型服务</th><th>代表模型</th><th>主要优势</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>Cohere</td><td>Command</td><td>企业级文本生成和理解能力</td><td>商业文档生成，客户支持</td></tr><tr><td>AI21</td><td>Jurassic-2</td><td>文本创作和摘要能力出色</td><td>内容创作，文档摘要</td></tr><tr><td>百度文心</td><td>文心一言</td><td>中文处理能力强</td><td>中文内容创作，本地化服务</td></tr><tr><td>阿里通义</td><td>通义千问</td><td>中文语境理解深入</td><td>中文对话，行业应用</td></tr><tr><td>讯飞星火</td><td>星火认知</td><td>垂直领域优化</td><td>特定行业应用，专业知识</td></tr></tbody></table><h2 id="开源模型" tabindex="-1"><a class="header-anchor" href="#开源模型"><span>开源模型</span></a></h2><h3 id="本地部署模型" tabindex="-1"><a class="header-anchor" href="#本地部署模型"><span>本地部署模型</span></a></h3><p>可在本地计算机或私有服务器部署的开源模型：</p><table><thead><tr><th>模型</th><th>大小变体</th><th>主要优势</th><th>资源需求</th></tr></thead><tbody><tr><td>Llama 3</td><td>8B, 70B</td><td>Meta最新开源模型，性能接近商业模型</td><td>8B: 16GB RAM, 70B: 48GB+ VRAM</td></tr><tr><td>Mistral</td><td>7B, 8x7B</td><td>高效架构，参数利用率高</td><td>7B: 16GB RAM, 8x7B: 32GB+ RAM</td></tr><tr><td>Gemma</td><td>2B, 7B</td><td>Google开源小模型，效率高</td><td>2B: 8GB RAM, 7B: 16GB RAM</td></tr><tr><td>Phi-3</td><td>Mini, Small</td><td>微软小参数高性能模型</td><td>Mini: 8GB RAM, Small: 16GB RAM</td></tr><tr><td>Vicuna</td><td>7B, 13B</td><td>基于Llama微调，指令遵循能力强</td><td>7B: 16GB RAM, 13B: 24GB RAM</td></tr><tr><td>Orca</td><td>7B, 13B</td><td>对齐优化的Llama模型</td><td>7B: 16GB RAM, 13B: 24GB RAM</td></tr><tr><td>Falcon</td><td>7B, 40B</td><td>多语言支持，开放训练过程</td><td>7B: 16GB RAM, 40B: 40GB+ VRAM</td></tr></tbody></table><p><strong>部署选项</strong>：</p><ul><li>GGUF 量化格式支持</li><li>CPU 和 GPU 加速</li><li>量化级别选择 (Q2_K to Q8_0)</li><li>内存映射优化</li></ul><h3 id="专业领域模型" tabindex="-1"><a class="header-anchor" href="#专业领域模型"><span>专业领域模型</span></a></h3><p>为特定任务优化的开源模型：</p><table><thead><tr><th>领域</th><th>代表模型</th><th>主要优势</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>代码生成</td><td>CodeLlama, DeepSeek Coder, WizardCoder</td><td>代码理解和生成专精</td><td>编程辅助，代码优化，调试</td></tr><tr><td>医疗健康</td><td>Med-PaLM M, Med42, ClinicalGPT</td><td>医疗知识丰富，专业术语理解</td><td>医学教育，临床参考，研究辅助</td></tr><tr><td>科学研究</td><td>Galactica, BLOOM</td><td>科学文献理解，数学能力强</td><td>科研辅助，论文写作，公式处理</td></tr><tr><td>法律分析</td><td>LexiLaw, Legal-Bert</td><td>法律术语和文档理解</td><td>法律文件分析，合规审查</td></tr><tr><td>多语言</td><td>BLOOM, XGLM</td><td>多语言支持广泛</td><td>多语言内容创建，翻译辅助</td></tr></tbody></table><h2 id="多模态模型" tabindex="-1"><a class="header-anchor" href="#多模态模型"><span>多模态模型</span></a></h2><p>支持处理文本以外模态的模型：</p><table><thead><tr><th>模型</th><th>支持模态</th><th>主要能力</th><th>推荐使用场景</th></tr></thead><tbody><tr><td>GPT-4V</td><td>文本，图像</td><td>高级图像理解和分析</td><td>图像内容分析，可视化问答</td></tr><tr><td>Claude 3 Vision</td><td>文本，图像，文档</td><td>精确文档理解和分析</td><td>文档处理，图表分析，视觉内容创作</td></tr><tr><td>Gemini Pro Vision</td><td>文本，图像，视频</td><td>视觉内容处理，实时分析</td><td>多媒体内容理解，视觉创意辅助</td></tr><tr><td>LLaVA</td><td>文本，图像</td><td>开源视觉-语言模型</td><td>本地图像分析，隐私保护应用</td></tr><tr><td>CogVLM</td><td>文本，图像</td><td>高精度视觉理解</td><td>细节图像描述，视觉内容理解</td></tr></tbody></table><h2 id="模型选择指南" tabindex="-1"><a class="header-anchor" href="#模型选择指南"><span>模型选择指南</span></a></h2><p>如何为您的需求选择合适的模型：</p><h3 id="选择因素" tabindex="-1"><a class="header-anchor" href="#选择因素"><span>选择因素</span></a></h3><p>在选择模型时考虑以下因素：</p><ol><li><p><strong>任务复杂度</strong>：</p><ul><li>简单任务：GPT-3.5-Turbo, Claude 3 Haiku, 本地小型模型</li><li>中等复杂任务：GPT-4, Claude 3 Sonnet, Gemini Pro</li><li>高度复杂任务：GPT-4o, Claude 3 Opus, 大型专业模型</li></ul></li><li><p><strong>响应速度需求</strong>：</p><ul><li>高速响应：Claude 3 Haiku, GPT-3.5-Turbo, 本地优化模型</li><li>平衡速度与质量：GPT-4, Claude 3 Sonnet</li><li>优先质量：GPT-4o, Claude 3 Opus</li></ul></li><li><p><strong>成本考虑</strong>：</p><ul><li>低成本：本地开源模型，GPT-3.5-Turbo</li><li>中等成本：Claude 3 Sonnet, Gemini Pro</li><li>高成本高性能：GPT-4o, Claude 3 Opus</li></ul></li><li><p><strong>特殊能力需求</strong>：</p><ul><li>代码生成：CodeLlama, WizardCoder, GPT-4</li><li>多语言：BLOOM, GPT-4, Claude 3</li><li>视觉理解：GPT-4V, Claude 3 Vision, Gemini Vision</li></ul></li><li><p><strong>隐私与安全</strong>：</p><ul><li>最高隐私：本地部署开源模型</li><li>中等隐私：私有云部署</li><li>标准隐私：商业API模型(遵循其隐私政策)</li></ul></li></ol><h3 id="性能比较表" tabindex="-1"><a class="header-anchor" href="#性能比较表"><span>性能比较表</span></a></h3><p>主要模型在不同任务上的性能对比：</p><table><thead><tr><th>任务类型</th><th>顶级性能</th><th>良好平衡</th><th>资源效率</th></tr></thead><tbody><tr><td>通用对话</td><td>GPT-4o, Claude 3 Opus</td><td>Claude 3 Sonnet, Llama 3 70B</td><td>Mistral 7B, Phi-3</td></tr><tr><td>创意写作</td><td>Claude 3 Opus, GPT-4</td><td>Claude 3 Sonnet, Llama 3</td><td>GPT-3.5, Gemma</td></tr><tr><td>代码生成</td><td>GPT-4, DeepSeek Coder</td><td>CodeLlama, WizardCoder</td><td>Phi-3, Mistral</td></tr><tr><td>逻辑推理</td><td>GPT-4o, Claude 3 Opus</td><td>GPT-4, Gemini Pro</td><td>Mistral, Phi-3</td></tr><tr><td>多语言处理</td><td>GPT-4o, Claude 3 Opus</td><td>BLOOM, Gemini Pro</td><td>XGLM, Mistral</td></tr><tr><td>视觉理解</td><td>GPT-4V, Gemini Pro Vision</td><td>Claude 3 Vision, LLaVA</td><td>CogVLM, LLaVA-NeXT</td></tr></tbody></table><h2 id="模型版本更新" tabindex="-1"><a class="header-anchor" href="#模型版本更新"><span>模型版本更新</span></a></h2>',42)),d("p",null,[t[1]||(t[1]=e("DeepChat 会定期更新支持的模型列表。查看最新支持的模型，请访问我们的")),d("a",G,[t[0]||(t[0]=e("模型更新页面")),l(i)]),t[2]||(t[2]=e("或在应用内查看模型配置面板。"))]),d("p",null,[t[4]||(t[4]=e("下一步，您可以了解如何")),l(r,{to:"/guide/model-integration/config-guide.html"},{default:s(()=>t[3]||(t[3]=[e("配置这些模型")])),_:1,__:[3]}),t[5]||(t[5]=e("，以便在 DeepChat 中使用它们。"))]),t[7]||(t[7]=d("p",null,[d("img",{src:"https://deepchat.thinkinai.xyz/chat-screenshot.png",alt:"支持的模型概览"})],-1)),t[8]||(t[8]=d("p",null,[d("em",null,"这里应放置一张展示 DeepChat 支持的各种模型的概览图，显示模型类别和关系。")],-1))])}const b=n(u,[["render",g]]),B=JSON.parse('{"path":"/guide/model-integration/supported-models.html","title":"支持的模型","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"商业云模型","slug":"商业云模型","link":"#商业云模型","children":[{"level":3,"title":"OpenAI 模型","slug":"openai-模型","link":"#openai-模型","children":[]},{"level":3,"title":"Anthropic 模型","slug":"anthropic-模型","link":"#anthropic-模型","children":[]},{"level":3,"title":"Google 模型","slug":"google-模型","link":"#google-模型","children":[]},{"level":3,"title":"其他商业模型","slug":"其他商业模型","link":"#其他商业模型","children":[]}]},{"level":2,"title":"开源模型","slug":"开源模型","link":"#开源模型","children":[{"level":3,"title":"本地部署模型","slug":"本地部署模型","link":"#本地部署模型","children":[]},{"level":3,"title":"专业领域模型","slug":"专业领域模型","link":"#专业领域模型","children":[]}]},{"level":2,"title":"多模态模型","slug":"多模态模型","link":"#多模态模型","children":[]},{"level":2,"title":"模型选择指南","slug":"模型选择指南","link":"#模型选择指南","children":[{"level":3,"title":"选择因素","slug":"选择因素","link":"#选择因素","children":[]},{"level":3,"title":"性能比较表","slug":"性能比较表","link":"#性能比较表","children":[]}]},{"level":2,"title":"模型版本更新","slug":"模型版本更新","link":"#模型版本更新","children":[]}],"git":{"createdTime":1742921049000,"updatedTime":1742921049000,"contributors":[{"name":"袁鑫","email":"eric.yuanxin@gmail.com","commits":1}]},"filePathRelative":"guide/model-integration/supported-models.md"}');export{b as comp,B as data};
